{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b37C239lFK3q"
   },
   "source": [
    "**DOG BREED CLASSIFICATION**\n",
    "\n",
    "This is a dog breed classification script which makes use of Transfer learning. A pre-trained Inception V3 is used as a feature extractor and the fully connected layers have been swapped with the custom dog breed classes.\n",
    "\n",
    "The Stanford Dog Dataset is used, which contains 120 breeds of dog and has more than 20000 images.\n",
    "\n",
    "Dataset Reference\n",
    "Primary:\n",
    "  Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao and Li Fei-Fei. Novel dataset for Fine-Grained Image Categorization. First Workshop on Fine-Grained Visual Categorization (FGVC), IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011.  [pdf]  [poster]  [BibTex]\n",
    "\n",
    "Secondary:\n",
    "  J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and L. Fei-Fei, ImageNet: A Large-Scale Hierarchical Image Database. IEEE Computer Vision and Pattern Recognition (CVPR), 2009.  [pdf]  [BibTex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHU1UZF4el76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpjscK4gGszh"
   },
   "source": [
    "All the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "xDkmPkKrTaAq",
    "outputId": "0ca03961-4d45-4322-ecaf-97e55aef2910"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0528 21:46:48.592976 16236 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras.layers as layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kCebdjjsTpoR",
    "outputId": "3ab45542-0c11-4987-aaf2-73463750321c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hVr7zpFEGwwu"
   },
   "source": [
    "The compressed image file is downloaded from 'http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar ' and decompressed into keras' cache folder.\n",
    "\n",
    "The get_file() function of the keras.utils returns the file path which is stored in data_root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6DX_6-gATwO2",
    "outputId": "4e86327c-47af-48c1-8732-4df4745c941f"
   },
   "outputs": [],
   "source": [
    "data_root = tf.keras.utils.get_file('Images' , 'http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar' , untar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oUT2HqbmHSPG"
   },
   "source": [
    "Confirming the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7MekN6c1UV5U",
    "outputId": "ccbbd7de-88ef-426a-d230-bff9fb7e3512"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls /root/.keras/datasets/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqEZoxlYHWWr"
   },
   "source": [
    "The bottom pre-trained weight vectors of Inception model is downloaded from tfhub.\n",
    "Link:- \"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/3 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GdQmCnEbYB4"
   },
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIQqzDwwHsAQ"
   },
   "source": [
    "Creating the module and getting the image size on which the Inception model was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qDU7tesGbyV3",
    "outputId": "6687ccb1-a908-40f4-b096-7570793ec9b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ajax9\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 21:47:51.282402 16236 deprecation.py:323] From C:\\Users\\ajax9\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[299, 299]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_extractor(x):\n",
    "  feature_extractor_module = hub.Module(feature_extractor_url)\n",
    "  return feature_extractor_module(x)\n",
    "\n",
    "IMAGE_SIZE = hub.get_expected_image_size(hub.Module(feature_extractor_url))\n",
    "\n",
    "IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USsXTZBRH-rW"
   },
   "source": [
    "Image generator to pre-process the images and scale them so that the data is in range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LumN7476IQd_"
   },
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGYrVVZHIxjB"
   },
   "source": [
    "All the images in the diectory are rescaled to the image size accepted by Inception model.\n",
    "The resulting object is an iterator which returns image and label batch pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j4xm3vUJcND3",
    "outputId": "4dee5df9-5524-4358-ed9a-0a0f39b234cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16835 images belonging to 99 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data = image_generator.flow_from_directory(str(data_root) , target_size = IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "odb6jDpacicr",
    "outputId": "061be4f1-d942-4ab3-eec1-6dc7f2a51683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 299, 299, 3)\n",
      "(32, 99)\n"
     ]
    }
   ],
   "source": [
    "for img , lab in image_data:\n",
    "  print(img.shape)\n",
    "  print(lab.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6brRaZyQJMvM"
   },
   "source": [
    "Wrapping the layers in a keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlxnT_bCc0QP"
   },
   "outputs": [],
   "source": [
    "feature_extractor_layer = layers.Lambda(feature_extractor , input_shape  = IMAGE_SIZE + [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzqJKINSJYrO"
   },
   "source": [
    "Freezing the bottom layers so that they arent trained again and only the new custom layer is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9xe5TWddJYi"
   },
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txS_C308JiB5"
   },
   "source": [
    "Building the custom model with feature extracting layer of Inception on top of custom layer with softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "Dx-zBcHVdPC_",
    "outputId": "a9412a28-1baf-4b17-c65d-af2a427312b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 21:48:16.831165 16236 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 99)                202851    \n",
      "=================================================================\n",
      "Total params: 202,851\n",
      "Trainable params: 202,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    layers.Dense(image_data.num_classes , activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IoAjM3YJ3Fz"
   },
   "source": [
    "Initializing the tfHub module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aUhinbqdxsU"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "sess = K.get_session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yykMyglrJ608"
   },
   "source": [
    "Confirming the resultant shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3Sx8LmKGeWnb",
    "outputId": "b7a9e700-aec8-444d-849c-ef0a02570b26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 99)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(img)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThMl-dTVKBwF"
   },
   "source": [
    "Configuring the training process. \n",
    "\n",
    "\n",
    "*   Using Adam optimizer to optimize the output to maximum accuracy\n",
    "*   Loss as 'categorical crossentropy' as, multiclass classifiction\n",
    "*   Metrics as accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07EnaO1zfWKC"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiQibacJKnPO"
   },
   "source": [
    "To visualize the training progress during every epoch,  a custom callback to log the loss and accuract of each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8Mtn6Qpf8cr"
   },
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "    \n",
    "  def on_batch_end(self , batch , logs = None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['acc'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tzGzbiLoh0XA",
    "outputId": "0a56c57c-7c70-4002-fe69-35e65b100256"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = image_data.samples//image_data.batch_size\n",
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3AgNAjUCK9GF"
   },
   "source": [
    "Training the model for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "apyo6jPJhoD0",
    "outputId": "bd9ff985-3335-4945-f9d0-5f999f403c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ajax9\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 21:48:36.506582 16236 deprecation.py:323] From C:\\Users\\ajax9\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "526/526 [==============================] - 3160s 6s/step - loss: 0.6953 - acc: 0.8397\n",
      "Epoch 2/5\n",
      "526/526 [==============================] - 3020s 6s/step - loss: 0.2549 - acc: 0.9168\n",
      "Epoch 3/5\n",
      "202/526 [==========>...................] - ETA: 14:20:44 - loss: 0.1891 - acc: 0.9386"
     ]
    }
   ],
   "source": [
    "batch_stats = CollectBatchStats()\n",
    "\n",
    "model.fit(\n",
    "    (items for items in image_data),\n",
    "    epochs = 5,\n",
    "    steps_per_epoch = steps,\n",
    "    callbacks = [batch_stats]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ItdX9cLLCT6"
   },
   "source": [
    "Plotting the loss and accuracy in every training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "colab_type": "code",
    "id": "guVibGTZiopC",
    "outputId": "08d621a2-5b78-4d3d-aacc-779203c898ba"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(batch_stats.batch_losses)\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(batch_stats.batch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CewM-3WtLI4W"
   },
   "source": [
    "Ordering the class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b7pHwh535vBO",
    "outputId": "40345274-d09f-4b0e-f67e-e33c10aa6d7c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])\n",
    "label_names = np.array([key.title() for key, value in label_names])\n",
    "label_names.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAqjXjAdLV8d"
   },
   "source": [
    "Formatting the string to get only the breed name, omitting everything efore the ' - '."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwyAXc6cCtsZ"
   },
   "outputs": [],
   "source": [
    "def formatString(x):\n",
    "  i = x.find('-')\n",
    "  return x[i+1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BlIREMWOLhfk"
   },
   "source": [
    "Predicting breeds of input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R4MmarkQ59Cv",
    "outputId": "ccccbf93-8f81-4333-cfe4-bbe7f9a84d1e"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "image1 = image.load_img('thumbnail-1477089693232.jpg' , target_size=IMAGE_SIZE)\n",
    "img_tensor = image.img_to_array(image1)\n",
    "img_tensor = np.expand_dims(img_tensor , axis=0)\n",
    "img_tensor /= 255.\n",
    "\n",
    "result_batch = model.predict(img_tensor)\n",
    "\n",
    "labels_batch = label_names[np.argmax(result_batch, axis=-1)]\n",
    "unformatted_prediction = labels_batch[0]\n",
    "prediction = formatString(unformatted_prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "S28nvGUd6Lbh",
    "outputId": "ac1bc51d-d6f1-4948-d8e7-95ee098a9a75"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plt.subplot(6,5,1)\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.title(formatString(labels_batch[0]))\n",
    "plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6UsLnde6V1h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dog_breed_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
